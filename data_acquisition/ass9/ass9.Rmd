---
title: "Assignment 9"
author: "Adrian Bracher (Matr. Nr. 01637180)"
date: "19.05.2021"
always_allow_html: true
output:
  pdf_document: 
    toc: true 
    toc_depth: 3
    number_sections: true 
    
---

# Preparing to analyze survey data
Note: Sadly Datacamp fails to provide a lot of necessary data and other prerequisites, therefore I cannot execute many of the code chunks.

```{r echo=T, error=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(irr)
library(psych)
library(psychometric)
library(dplyr)
library(likert)
library(car)
library(Hmisc)
library(tidyr)
library(corrplot)
library(lavaan)
```


## Measuring expert agreement
In this exercise we learn how to use cor() to compute the correlation in a data frame and then also call agree() to get the agreement in percent between raters.

```{r eval=F}
# Print beginning of sme data frame
print(head(sme))

# Correlation matrix of expert ratings
cor(sme)

# Percentage agreement of experts
agree(sme)
```

## Inter-rater reliability
In the code below we learn how to compute Cohen's Kappa.
```{r eval=F}
# Load psych package
library(psych)

# Check inter-rater reliability
cohen.kappa(sme)
```

## Content validity
Here we measure content validity using Lawshe's Content Validity Ratio with CVratio().
```{r eval=F}
# Calculate the CVR for each unique item in the data frame
cvr_by_item <- lawshe %>% 
  group_by(item) %>% 
  summarize(CVR = CVratio(NTOTAL = length(unique(expert)),
                      NESSENTIAL = sum(rating == 'Essential')))

# See the results
cvr_by_item
```

## Visualizing response frequencies
In this exercise we derive summary counts and create a visualization.
```{r}
brand_rep = read.csv("brandrep-cleansurvey-extraitem.csv")
# Convert items to factor
b_rep_likert <- brand_rep %>% 
              	mutate_if(is.integer, as.factor)

# Response frequencies - base R
summary(b_rep_likert)

# Plot response frequencies
result <- likert(b_rep_likert)
plot(result)
```

## Reverse-coding items
In the code below we "reverse-code" items. 
```{r eval=F}

# Get response frequencies from psych
response.frequencies(brand_qual)

# Print item descriptions
brand_qual_items

# Reverse code the "opposite" item
brand_qual$tired_r <- recode(brand_qual$tired, 
                            "1 = 5; 2 = 4; 4 = 2; 5 = 1")

# Check recoding frequencies
brand_qual %>% 
	select(tired, tired_r) %>%
	response.frequencies() %>%
	round(2)
```

## Missing values
Missing values sometimes hint at underlying problems. In this exercise we try to analyze the missing values to see more.
```{r eval=F}
# Total number of rows
nrow(missing_lots)

# Total number of complete cases
nrow(na.omit(missing_lots))

# Number of incomplete cases by variable
colSums(is.na(missing_lots))

# Hierarchical plot -- what values are missing together?
plot(naclus(missing_lots))
```

## Exploring item correlations
Here we visualize item correlations with corrplot.
```{r eval=F}
# View significance of item correlations
corr.test(brand_qual_9)

# Visualize item correlations -- corrplot
corrplot(cor(brand_qual_9), method = "circle")
```

## Preparing the brand reputation survey
In this exercise we revisit recode and then use select with a "-" to drop a certain column. We then visualize the correlations in the modified data frame.
```{r eval=F}
# Get response frequencies
response.frequencies(brand_rep_9)

# Recode the appropriate item 
b_rep_items
brand_rep_9$poor_workman_r <- recode(brand_rep_9$poor_workman,   
							"1 = 5; 2 = 4; 4 = 2; 5 = 1")

# Drop poor_workman from brand_rep_9: brand_rep_9_new
brand_rep_9_new <- select(brand_rep_9, -poor_workman)

# Visualize item correlation
corrplot(cor(brand_rep_9_new), method = "circle")
```

# Exploratory factor analysis & survey development
## From correlations to factors
We repeat what we've learned in the previous chapter. Note that corr.test creates a correlation matrix (table). Then, we make a parallel analysis. 
```{r}
b_loyal_10 = read.csv("brandloyalty.csv")
# Print correlation matrix
corr.test(b_loyal_10)

# Visualize b_loyal_10 correlation matrix
corrplot(cor(b_loyal_10))

# Parallel analysis
fa.parallel(b_loyal_10)
```

## Building your first EFA
In this exercise we build an EFA using the psych package. We also plot a scree plot of the model.
```{r}
brand_rep_9 = read.csv("brandrep-cleansurvey-extraitem.csv")
# Scree plot
scree(brand_rep_9)

# Conduct three-factor EFA
brand_rep_9_EFA <- fa(brand_rep_9,  nfactors = 3)

# Print output of EFA
names(brand_rep_9_EFA)
```

## EFA: How many factors?
Here we look into different number of factors and then print the loadings for a two/four factor EFA.
```{r eval=F}
brand_rep_9_EFA_3 = brand_rep_9_EFA
# Summarize results of three-factor EFA
summary(brand_rep_9_EFA_3)

# Build and print loadings for a two-factor EFA
brand_rep_9_EFA_2 = fa(brand_rep_9, nfactors = 2)
brand_rep_9_EFA_2$loadings


# Build and print loadings for a four-factor EFA
brand_rep_9_EFA_4 = fa(brand_rep_9, nfactors = 4)
brand_rep_9_EFA_4$loadings
```

## Refining the brand reputation survey 
We extract further information like eigenvalues and factor score correlations.
```{r}
# Three factor EFA - brand_rep_9
brand_rep_9_EFA_3 <- fa(brand_rep_9, nfactors = 3)

# Eigenvalues
brand_rep_9_EFA_3$e.values

# Factor score correlations
brand_rep_9_EFA_3$score.cor

# Factor loadings
brand_rep_9_EFA_3$loadings
```

## Comparing EFA model fits
In this exercise we repeat the previously learned usage of fa, select and their variables.
```{r}
# Create brand_rep_8 data frame
brand_rep_8 <- select(brand_rep_9, -one_of_a_kind)

# Create three-factor EFA
brand_rep_8_EFA_3 <- fa(brand_rep_8, nfactors=3)

# Factor loadings
brand_rep_8_EFA_3$loadings

# Factor correlations -- 9 versus 8 item model
brand_rep_9_EFA_3$score.cor
brand_rep_8_EFA_3$score.cor

```

## EFA model iteration
Again, in this exercise we use previously learned functions to compute loadings and a scree plot.
```{r}
# Three factor EFA loadings
brand_rep_8_EFA_3$loadings

# Two factor EFA & loadings
brand_rep_8_EFA_2 <- fa(brand_rep_8, nfactors = 2)
brand_rep_8_EFA_2$loadings

# Four factor EFA & loadings
brand_rep_8_EFA_4 <- fa(brand_rep_8, nfactors = 4)
brand_rep_8_EFA_4$loadings

# Scree plot of brand_rep_8
scree(brand_rep_8)
```

## Measuring coefficient (Cronbach's) alpha
Here we use the function alpha() to calculate Cronbach's coefficient.
```{r}
brand_rep_9 = read.csv("brandrep-cleansurvey-extraitem.csv")
# Standardized coefficient alpha
psych::alpha(brand_rep_9)$total$std.alpha

# 3-factor EFA
brand_rep_9_EFA_3 <- fa(brand_rep_9, nfactors = 3)
brand_rep_9_EFA_3$loadings

# Standardized coefficient alpha - refined scale
psych::alpha(brand_rep_8)$total$std.alpha
```

## Coefficient alpha by dimension
We use the previously learned functions to check the standardized alpha for each of the three dimensions "Product Quality", "Willingness to Pay" and "Product Differentiation".
```{r}
# Get names of survey items
names(brand_rep_8)

# Create new data frames for each of three dimensions
p_quality <- brand_rep_8[1:3]
p_willingness <- brand_rep_8[4:6]
p_difference <- brand_rep_8[7:8]

# Check the standardized alpha for each dimension
psych::alpha(p_quality)$total$std.alpha
psych::alpha(p_willingness)$total$std.alpha
psych::alpha(p_difference)$total$std.alpha
psych::alpha(brand_rep_8)$total$std.alpha
```

## Split-half reliability
In this exercise we use the function splitHalf() to compute the split-half reliability of brand_rep_8.
```{r}
# Get split-half reliability 
splitHalf(brand_rep_8)

# Get averages of even and odd row scores
even_items <- colMeans(brand_rep_8[,c(FALSE,TRUE)])
odd_items <- colMeans(brand_rep_8[,c(TRUE,FALSE)])

# Correlate scores from even and odd items
cor(even_items, odd_items)

# Get Cronbach's alpha
psych::alpha(brand_rep_8)
```

## Measuring loyalty
In this exercise we learn by repetition to compute EFAs.
```{r}
# 3 factor EFA
b_loyal_10_EFA_3 <- fa(b_loyal_10, nfactors = 3)

# Factor loadings, eigenvalues and factor score correlations
b_loyal_10_EFA_3$loadings
b_loyal_10_EFA_3$e.values
b_loyal_10_EFA_3$score.cor

# 2 factor EFA
b_loyal_10_EFA_2 <- fa(b_loyal_10, nfactors = 2)

# Factor loadings, eigenvalues and factor score correlations
b_loyal_10_EFA_2$loadings
b_loyal_10_EFA_2$e.values
b_loyal_10_EFA_2$score.cor
```

# Confirmatory factor analysis & construct validation
## Factor loadings in EFA & CFA
We learn how we can print CFA loadings with inspect() and also plot CFA diagrams via semPaths().
```{r eval=F}
# Factor loadings -- EFA
brand_rep_EFA$loadings

# Factor loadings -- CFA
inspect(brand_rep_CFA, what = "std")$lambda

# Plot diagram -- EFA
fa.diagram(brand_rep_EFA)

# Plot diagram -- CFA
semPaths(brand_rep_CFA)
```

## Building a CFA in lavaan
Here we use the package lavaan to build a CFA and summarise the results. CFA allows the researcher to test the hypothesis that a relationship between manifest and latent variables exist. Unlike EFA, we define the relationships between variables and we have a specific theory to test.
```{r}
b_loyal_10 = read.csv("brandloyalty.csv")
# Rename items based on proposed dimensions
colnames(b_loyal_10) <- c("ID1", "ID2", "ID3", 
                        "PV1", "PV2", "PV3", 
                        "BT1", "BT2", "BT3", "BT4")

# Define the model
b_loyal_cfa_model <- 'ID =~ ID1 + ID2 + ID3
                    PV =~ PV1 + PV2 + PV3
                    BT =~ BT1 + BT2 + BT3 + BT4'
                        
# Fit the model to the data
b_loyal_cfa <- cfa(model = b_loyal_cfa_model, data = b_loyal_10)

# Check the summary statistics -- include fit measures and standardized estimates
summary(b_loyal_cfa, fit.measures = TRUE,
        standardized = TRUE)
```

## A not-so-good CFA
In the code below we create two_dimensions ODD and EVEN according to specification and then fit a cfa model to them. 
```{r eval=F}
# Two dimensions: odd- versus even-numbered items
c_sat_bad_model <- 'ODD =~ CS1 + CS3 + CS5 + CS7 + CS9
				EVEN =~ CS2 + CS4 + CS6 + CS8 + CS10'
                
# Fit the model to the data
c_sat_bad_CFA <- cfa(model = c_sat_bad_model, data = c_sat)

# Summary measures
summary(c_sat_bad_CFA, fit.measures = TRUE, standardized = TRUE)
```

## Adjusting for non-normality
Multivariate normal distribution is an assumption under CFA. In this exercise we learn how to check that.
```{r eval=F}
# Mardia's test for multivarite normality
mardia(c_sat_50)

# Fit model to the data using robust standard errors
c_sat_cfa_mlr <- cfa(model = c_sat_model,
                     data = c_sat_50,
                     estimator = "MLR")

# Summary including standardized estimates and fit measures
summary(c_sat_cfa_mlr, fit.measures = TRUE, standardized = TRUE)
```

## Comparing models using absolute fit measures
In this exercise we compare models using lavaan and determine which model fits better.
```{r eval=F}
# Fit the models to the data
c_sat_cfa_a <- cfa(model = c_sat_model_a, data = c_sat)
c_sat_cfa_b <- cfa(model = c_sat_model_b, data = c_sat)

# Print the model definitions
cat(c_sat_model_a)
cat(c_sat_model_b)

# Calculate the desired model fit statistics
fitMeasures(c_sat_cfa_a, fit.measures = c("cfi", "tli"))
fitMeasures(c_sat_cfa_b, fit.measures = c("cfi", "tli"))
```

## Comparing CFA models using ANOVA
In this exercise we use analysis of variance (ANOVA) to compare nested models.
```{r  eval=F}
# View current c_sat model
cat(c_sat_model_a)

# Add EU1 to the CSU factor
c_sat_model_b <- 'CSU =~ CSU1 + CSU2 + CSU3 + CSU4 + EU1
                EU =~ EU1 + EU2 + EU3
                PS =~ PS1 + PS2 + PS3'

# Fit Models A and B to the data
c_sat_cfa_a <- cfa(model = c_sat_model_a, data = c_sat)
c_sat_cfa_b <- cfa(model = c_sat_model_b, data = c_sat)

# Compare the nested models
anova(c_sat_cfa_a, c_sat_cfa_b)
```

## Group CFA
In the code below we learn how to add groups to a cfa model.
```{r eval=F}
# Fit the model to the data 
c_sat_cfa <- cfa(model = c_sat_model, data = c_sat_group, group = "COUNTRY")

# Summarize results -- include fit measures and standardized estimates
summary(c_sat_cfa, fit.measures = TRUE, standardized = TRUE)

# Get average estimate for both groups
standardized_solution <- standardizedSolution(c_sat_cfa)
standardized_solution %>%
	filter(op == "=~") %>% 
	group_by(group) %>% 
	summarize(mean(est.std))
```

## Construct validity & model fit
In the code below we use different reliability measures.
```{r  eval=F}
# Fit three-factor CFA
c_sat_cfa_3 <- cfa(model = c_sat_cfa_model_3, data = c_sat)

# Inspect key fit measures - three-factor CFA
fitMeasures(c_sat_cfa_3, fit.measures = c("cfi","tli","rmsea"))

# Fit two-factor CFA
c_sat_cfa_2 <- cfa(model = c_sat_cfa_model_2, data = c_sat)

# Inspect key fit measures - two-factor CFA
fitMeasures(c_sat_cfa_2, fit.measures = c("cfi","tli","rmsea"))

# Compare measures of construct validity for three- versus two-factor models
reliability(c_sat_cfa_3)
reliability(c_sat_cfa_2)
```

## Construct validity & reliability
In this exercise, we find out how we can measure validity and realiability.
```{r  eval=F}
# Print CFA model
cat(brand_rep_CFA_model)

# semTools reliability measures
reliability(brand_rep_CFA)

# psych coefficient alpha measure
alpha(brand_rep_9)$total$std.alpha
```

## Deeper into AVE & CR
In this exercise we compare dplyr methods to semTools methods and compute reliability scores.
```{r  eval=F}
# Store F1 estimates as object loadings	
loadings <- standardizedSolution(c_sat_cfa) %>%	
 filter(op == "=~", lhs == "F1") %>% select(est.std)	
 
# Composite reliability -- the squared sum of all loadings divided by that same figure plus the sum of 1 minus the loadings squared	
com_rel <- sum(loadings) ^ 2 / ((sum(loadings)^ 2)  + sum(1 - loadings ^ 2))	
com_rel	

# Average variance extracted -- sum of all factor squares divided by the number of items	
avg_var <- sum(loadings ^ 2) / nrow(loadings)	
avg_var	

# Compare versus semTools
reliability(c_sat_cfa)
```

## CFA of the brand reputation survey
In this exercise we build a lavaan model and then print the summary and also construct validity with the reliability() function.
```{r eval=F}
# Print brand_rep_factors	
brand_rep_factors	

# Build model for lavaan	
brand_rep_8_cfa_model <- "QUAL =~ consistent + well_made + poor_workman_r	
				PRICE =~ go_up + lot_more + higher_price	
				UNIQUE =~ stands_out + unique"	
# Summarize results with fit measures and standardized estimates
summary(brand_rep_8_CFA, standardized = T, fit.measures = T)

# Construct validity
reliability(brand_rep_8_CFA)
```

# Criterion validity & replication 
## Preparing a scaled data frame
In this exercise we learn how to use scale() for scaling and then describe() to print descriptive statistics.

```{r eval=F}
# Check if brand_rep and brand_rep_spend have the same number of rows
same_rows <- nrow(brand_rep) == nrow(brand_rep_spend)
same_rows

# Append spend column to brand_rep
brand_rep <- cbind(brand_rep, brand_rep_spend)

# Scale the data
b_rep_scale <- scale(brand_rep)

# Compare descriptive statistics of raw and scaled data frames using psych
describe(brand_rep)
describe(b_rep_scale)
```

## Plotting and analyzing a concurrent validity model
We create a standardized model and establish concurrent validity. Then we print the standardized covariances with standardizedSolution() and plot the result with semPaths().
```{r eval=F}
# Correlate F1, F2 and F3 to spend_f, the 'latentized' spend
brand_rep_model <- 'F1 =~ well_made + consistent + poor_workman_r
					F2 =~ higher_price + lot_more + go_up
					F3 =~ stands_out + unique
					spend_f =~ spend
					spend_f ~~ F1 + F2 + F3'

# Fit the model to the data -- sem()
brand_rep_cv <- sem(data = brand_rep_scaled, model = brand_rep_model)

# Print the standardized covariances b/w spend_f and other factors
standardizedSolution(brand_rep_cv) %>% filter(rhs == "spend_f")

# Plot the model with standardized estimate labels
semPaths(brand_rep_cv, whatLabels = "est.std", edge.label.cex = .8)
```

## Concurrent validity & Likert-style items
In this exercise we learn by repetition.
```{r eval=F}
# Bind & scale the variables
c_sat_rec_scale <- cbind(c_sat, c_sat_recommend) %>% scale()

# Define the model - Rec_f covaries with F1, F2, F3
c_sat_rec_model <- 'F1 =~ CS1 + CS2 + CS3 + CS4
F2 =~ CS5 + CS6 + CS7
F3 =~ CS8 + CS9 + CS10
Rec_f =~ Rec_1
Rec_f ~~ F1 + F2 + F3'

# Fit the model to the data 
c_sat_rec_sem <- sem(model = c_sat_rec_model, data = c_sat_rec)

# Look up standardized covariances
standardizedSolution(c_sat_rec_sem) %>% filter(rhs == "Rec_f")
```

## Statistical significance & r-square
In this exercise we practice fitting models, summarizing results and plotting.
```{r  eval=F}
# Define the model
b_q_model <- 'HIP =~ trendy + latest + tired_r
            VALUE =~ happy_pay + reason_price + good_deal
            PERFORM =~ strong_perform + leader + serious
            spend ~ HIP + VALUE + PERFORM'

# Fit the model to the data
b_q_pv <- sem(data = b_q_scale, model = b_q_model)

# Check fit, r-square, standardized estimates
summary(b_q_pv, standardized = T, fit.measures = T, rsquare = T)

# Plot the model -- rotate from left to right
semPaths(b_q_pv, rotation = 2, whatLabels = "est.std", edge.label.cex = .8)
```

## Prediction & causation
In the following we exercise the use of standardizedSolution(), inspect() and  semPaths().
```{r  eval=F}
# Plot the new model
semPaths(brand_rep_sem, rotation = 2)

# Get the coefficient information
standardizedSolution(brand_rep_sem) %>% filter(op == "~")

# Get the r-squared
r_squared <- inspect(brand_rep_sem, 'r2')["F2"]
r_squared
```

## Exploring factor scores
Factor scores represent individual respondents' standing on a latent factor. We learn how we can combine predict() with as.data.frame() to  compute such a factor score.
```{r  eval=F}
# Compute factor scores in lavaan -- store as data frame
brand_rep_scores <- as.data.frame(predict(brand_rep_cfa))

# Descriptive statistics of our factor scores
describe(brand_rep_scores)

# Plot histograms for each variable
multi.hist(brand_rep_scores)
# Are they normally distributed? Check using map()
map(brand_rep_scores, shapiro.test)
```

## Factor scores & regression
We learn how to combine lm with summary and round as well as inspect to compare results. 
```{r eval=F}
# Linear regression of standardized spending and factor scores
bq_fs_reg <- lm(spend ~ F1 + F2 + F3, data = bq_fs_spend)

# Summarize results, round estimates
rounded_summary <- round(summary(bq_fs_reg)$coef, 3)
rounded_summary

# Summarize the results of CFA model
summary(brand_qual_pv)

# Compare the r-squared of each
inspect_rsq <- inspect(brand_qual_pv, "r2")["spend"]
inspect_rsq
summary(bq_fs_reg)$r.squared
```

## Test-retest reliability
describeBy() returns descriptive statistics like describe(), but grouped.
testRetest() is used to measure the test-retest reliability of the survey.
```{r  eval=F} 
# Descriptive statistics grouped by 'time'
describeBy(brand_rep_t1_t2, "time")

# Test retest: time == 1 versus time == 2 by id = "id"
brand_rep_test_retest <- testRetest(t1 = filter(brand_rep_t1_t2, time == 1),
                                  t2 = filter(brand_rep_t1_t2, time == 2),
                                  id = "id")

# Access correlation of scales scores between t1 and t2
brand_rep_test_retest$r12
```

## CFA, EFA & replication
In this exercise we practice previously acquired knowledge.
```{r eval=F}
# Split data into odd and even halves
brand_rep_efa_data <- brand_rep[c(TRUE,FALSE),]
brand_rep_cfa_data <- brand_rep[c(FALSE,TRUE),]

# Get factor loadings of brand_rep_efa_data EFA
efa <- fa(brand_rep_efa_data, nfactors = 3)
efa$loadings

# Confirm the data that the model was fit to
inspect(brand_rep_cfa, what = "call")

# Check fit measures
fitmeasures(brand_rep_cfa)[c("cfi","tli","rmsea")]
```
